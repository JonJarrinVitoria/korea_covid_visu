{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adb8551",
   "metadata": {
    "id": "4adb8551"
   },
   "source": [
    "<center> \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5c/Logo_Mondragon_Unibertsitatea.png\" width=\"150\" height=\"100\" float =\"left\">\n",
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPIAAADQCAMAAAAK0syrAAAAgVBMVEX///8AAAD7+/t6enrV1dWYmJjj4+Po6OjQ0NDx8fGIiIjq6ur39/fv7+/09PTf39+vr69xcXHGxsa5ubmfn59paWmnp6eTk5M8PDxZWVm9vb1eXl5ubm7BwcEzMzOHh4cnJycdHR0TExNPT09FRUUYGBhaWlpEREQ4ODgqKipjY2MMKFclAAAEmElEQVR4nO3ZaXOyPBQGYG52VzbFfQO1tf//Bz5JqArYzvSd8IK29/Whg4ymJyQ5WTAMIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiKiXyXYdB1B2yxg0nUM7VoBWHcdRKumiO2/1cozbIwQQddhtMhH3zDO6DqMFpnYGsYYTtdxtGiKkWHs0Os6jvb4SA1jhGnXcbRoL7q1kcPrOo72JHANka6truNokazsGH8pXacwDeMNftdxtEjOTX3MdIrworipaNowET16g4VWGXvYDUXTCjFBBXIloiHU6yNtm8HwcDC1ynit1Gci7GGvV+PwtXZgMwSYa5YB6D2ylgH40Cyij10jobQkhXa8Lmor1WR/S/+2P9QsvXEBsNQtY4u8/DE+wHI/rzd4uv3oBPprrj5QWoaICjulge2FI93yG9WbN3C+F6M0Q9nbp2vVihRRqn3YNcK97wZ5MxU2jeR/OVC3T6JPL7SXEJmocnGW4p7l8Zm2wS5aA1EDJdULXqj4tLP129zEWV4EC6zqw3ZQydaelVuPfcq03crHqdy6zxp5eBWjCIuBIc9/NPc/K5i23FD4C6wfjlQmyEqfQsBaVKaHvhgGlugkSG63bNUGNrDXi6vOXeOteNwp9GbNHCNR63hzAeaPJ4WV2SDFxRSPuLT78ETuPItnHhxw/GzpQC1cZzjhoBVXjZ8jv270rB8P5SB10tivbhA9bE25DrmyqqtOq3ywJL42NHoZxvdbB/kb1cvEVJkve+qWvbQwFVVvbiz3ROnRffDk7z/7meiUKsByfjd3Kj1PcViqqoq+XTkT7pcX3l6GhR/hXOpUC1nedTcSi4yl/sV+HYpCjo29NVnmQFpuisNPzgWGM8gj3yUsb4fT8BbjWlZwUNqSTHC6/0rU6NbI40g9r6jcSXJ5p7xqG3oDBxd1GTW0+15+iCBqRxff9h/Pes+wSkbmQP5MtYWqgdyD7PrRu5iLiy5qlU9DrNsGxYPIS2Fx7Voi/75Vj09tzEWOQj3FA33T9OcNzO4j3zmK+j4uLb+bo0LZBPtihB6LfBqh+LuyVqtdeM3O4+ppykV2B0O2dyI69lFcDSYH7Mayjtl9PMVH+T08zkQj1fYfbv3+z02BbLtVcTtfDo5vquxAheOLlHtNN+Mivkst3/VLE4yhlmLis53Jpu8VT2xbPAS5Ll0lgRvETo6tav9088Um23Q1Xx/44WTmhPG3pXx9WC/GbjFCrXsWWapuWn//bNYPgMRT+phfW2+ThuWtY7JSfWeaDv5bJZr15Vh2EDvFOLRwiy5RGeXw0Mj1PGMv8tlTv8vD6vFeKBYQoZov3VInGIsuuzyh2kAuXu9VZfY4LydyNIYyZ/qVo225R6w3afiZrV7J40YqVF1apJ7JtPml/TOY1d8xTD7X/fY8izSmiifm11J2/w+8issqCyC1V/3tNqUl8vhS3uf8XtZtaZ98NWP9SmKpFQ6NYbLXP89+GcGHXAeeXm+G1RIET/cWhYiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIqFn/AA1nKx7ECwr8AAAAAElFTkSuQmCC\" width=\"200\" height=\"120\" float =\"left\">    \n",
    "\n",
    "\n",
    "---\n",
    "<h3>Beñat Basabe, Jon Jarrín, June Pagaldai, Daniel Puente, Eneko Rentería | <font color='red'> Equipo Rojo<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de grafos\n",
    "Se genera el grafo que posteriormente se empleará para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9a77d",
   "metadata": {
    "id": "50c9a77d"
   },
   "source": [
    "### Carga de librerias \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c963a89",
   "metadata": {
    "id": "6c963a89"
   },
   "source": [
    "- **General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d8baeb",
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1639141048326,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "47d8baeb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def guardar_pikle(df, name):\n",
    "    with open(dir_out + str(name) + '.pkl', 'wb') as fp: pickle.dump(df, fp)\n",
    "\n",
    "def abrir_pikle(name):\n",
    "    with open(dir_out + str(name) + '.pkl', 'rb') as fp: df = pickle.load(fp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2c59d",
   "metadata": {
    "id": "f8d2c59d"
   },
   "source": [
    "- **Pyspark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb04edd4",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1639141048708,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "bb04edd4"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c037de3",
   "metadata": {
    "id": "4c037de3"
   },
   "source": [
    "- **Strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cac86bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1639141048710,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "1cac86bb"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf59971",
   "metadata": {
    "id": "fdf59971"
   },
   "source": [
    "- **Visualización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0398c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1639141049805,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "dc0398c1"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3MzuEph_Z8Cg",
   "metadata": {
    "id": "3MzuEph_Z8Cg"
   },
   "source": [
    "* **Grafos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-lxS1ncRZwDT",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1639141049807,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "-lxS1ncRZwDT"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c8285",
   "metadata": {},
   "source": [
    "- **Otros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e484685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ab5c8",
   "metadata": {
    "id": "b09ab5c8"
   },
   "source": [
    "## Funciones a utilizar\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in, dir_out = \"../../datos/datos_originales/\", \"../../datos/datos_desarrollo/\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"how to read csv file\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae999b7",
   "metadata": {
    "id": "8ae999b7"
   },
   "source": [
    "- Función para **dar nombre** a la variable **family_id** mediante la variable title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b543aa1",
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1639141056405,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "2b543aa1"
   },
   "outputs": [],
   "source": [
    "def get_family_name(id_):\n",
    "    \n",
    "    filtered = product.filter(product.family_id == id_)\n",
    "    string = ' '.join([x['title'] for x in filtered.select('title').collect()]).lower()\n",
    "    \n",
    "    return id_, Counter(string.split()).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1fe385",
   "metadata": {
    "id": "ca1fe385"
   },
   "source": [
    "- Función para crear los **sufijos** y facilitar el *join*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60cdbe9c",
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1639141056407,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "60cdbe9c"
   },
   "outputs": [],
   "source": [
    "def rename_columns(df, suffix):\n",
    "    ''' Renombra las columnas de un dataframe.'''\n",
    "    for names in df.schema.names: df = df.withColumnRenamed(names,names + suffix)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20lh66ZdaJOU",
   "metadata": {
    "id": "20lh66ZdaJOU"
   },
   "source": [
    "* Función para conseguir valores únicos de una variable en *pyspark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3KNGJEaGCt",
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1639141056408,
     "user": {
      "displayName": "Eneko Renteria Gabantxo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11839893040904061534"
     },
     "user_tz": -60
    },
    "id": "7e3KNGJEaGCt"
   },
   "outputs": [],
   "source": [
    "def get_value(dffs, variable):\n",
    "    return list(dffs.select(dffs[variable]).distinct().toPandas()[variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1c70a",
   "metadata": {},
   "source": [
    "* Función que crea el grafo filtrando por temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61da94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_productos(e, variable, tallas = False):\n",
    "    if tallas:\n",
    "        list_1 = df_para_filtrar[(df_para_filtrar[variable] == e[0]) | (df_para_filtrar[variable] == 'UNQ')].index.to_list()\n",
    "        list_2 = df_para_filtrar[(df_para_filtrar[variable] == e[1]) | (df_para_filtrar[variable] == 'UNQ')].index.to_list()\n",
    "    else:\n",
    "        list_1 = df_para_filtrar[df_para_filtrar[variable] == e[0]].index.to_list()\n",
    "        list_2 = df_para_filtrar[df_para_filtrar[variable] == e[1]].index.to_list()\n",
    "\n",
    "    return list(itertools.product(list_1, list_2))\n",
    "\n",
    "def create_graph(o):\n",
    "    \n",
    "    ##############\n",
    "    ##### DF #####  \n",
    "    ##############\n",
    "\n",
    "    ### Filtrar por temporada ###\n",
    "    df2 = df.filter(df.season == o)\n",
    "    \n",
    "    ### Conseguir variantes de productos únicos#####\n",
    "    vu_id_product = get_value(df2, 'id_product')\n",
    "    \n",
    "    ### Crear df para filtrar ###\n",
    "    df_para_filtrar = pd.DataFrame(vu_id_product).reset_index()\n",
    "    df_para_filtrar['family_product'] = pd.Series([e[0] for e in df_para_filtrar[0].str.split('_')])\n",
    "    df_para_filtrar['level'] = df_para_filtrar.family_product.map(niveles)\n",
    "    df_para_filtrar.columns = ['index', 'id_product', 'family_product', 'level']\n",
    "    \n",
    "    def sacar_productos(e, variable, tallas = False):\n",
    "        if tallas:\n",
    "            list_1 = df_para_filtrar[(df_para_filtrar[variable] == e[0]) | (df_para_filtrar[variable] == 'UNQ')].index.to_list()\n",
    "            list_2 = df_para_filtrar[(df_para_filtrar[variable] == e[1]) | (df_para_filtrar[variable] == 'UNQ')].index.to_list()\n",
    "        else:\n",
    "            list_1 = df_para_filtrar[df_para_filtrar[variable] == e[0]].index.to_list()\n",
    "            list_2 = df_para_filtrar[df_para_filtrar[variable] == e[1]].index.to_list()\n",
    "\n",
    "        return list(itertools.product(list_1, list_2))\n",
    "\n",
    "    #############\n",
    "    ### NODOS ###\n",
    "    #############\n",
    "\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i in range(len(vu_id_product)):\n",
    "            G.add_node(i,\n",
    "                      color = vu_id_product[i].split('_')[1],\n",
    "                      size  = vu_id_product[i].split('_')[2],\n",
    "                      level = df_para_filtrar['level'][i])\n",
    "            \n",
    "    ###############        \n",
    "    ### ARISTAS ###\n",
    "    ###############\n",
    "\n",
    "    ### Aristas - Tallas ###\n",
    "    df_para_filtrar['talla'] = df_para_filtrar['id_product'].apply(lambda x:x.split('_')[-1])\n",
    "    orden_tallas = ['XXS', 'XS', 'S', 'M', 'L', 'XL', 'XXL', 'XXXL','X4XL']\n",
    "                \n",
    "    combinaciones_tallas_letra = []\n",
    "    for i in range(1, len(orden_tallas)): combinaciones_tallas_letra += [(orden_tallas[i - 1], orden_tallas[i])]\n",
    "    combinaciones_talla = list(map(sacar_productos, combinaciones_tallas_letra, ['talla'], [True]))[0]\n",
    "    \n",
    "    ### Aristas - Level ###\n",
    "    levels = get_value(df2.filter(df2.id_product.isin(vu_id_product)), 'level')\n",
    "    levels.sort()\n",
    "    tods = list(itertools.combinations(levels, 2))\n",
    "    tods.sort()\n",
    "    tods += [('3.2', '3.2')]\n",
    "    tods.remove(('1.1', '1.2'))\n",
    "\n",
    "    combinaciones_level = list(map(sacar_productos, tods, ['level']))[0]\n",
    "    \n",
    "    ### Se añaden todas las aristas ###\n",
    "    G.add_edges_from(list(set(combinaciones_level + combinaciones_talla)))\n",
    "\n",
    "    ### Se empieza poniendo un peso de 0 a todas las aristas ###\n",
    "    for x in G.edges(): G[x[0]][x[1]]['weight'] = 1\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(dir_out + 'lookiero_*.csv', header=True, inferSchema=True)\n",
    "df_total = spark.read.csv(dir_out + 'df_total.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"level\",col(\"level\").cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+-----------+-------------+---------+--------------------+--------------+----------+-------------+-----+------------+---------------+--------------------+------------------+-----+\n",
      "|                  id|season|stock|publishable|size_lookiero|    color|          id_product|family_product|name_brand| origin_brand|value|name_feature|multiple_values|      feature_family|id_product_feature|level|\n",
      "+--------------------+------+-----+-----------+-------------+---------+--------------------+--------------+----------+-------------+-----+------------+---------------+--------------------+------------------+-----+\n",
      "|498662e5-11e8-483...|     8|    0|       true|            M|     ecru|   cardigan_ecru_M_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|dcda2fe4-58e3-4b2...|     8|    0|       true|            S|     ecru|   cardigan_ecru_S_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|d54e064c-9f90-4ea...|     8|    0|       true|            L|     ecru|   cardigan_ecru_L_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|3112fc7f-5b4d-4c3...|     8|    0|       true|            S|    brown|  cardigan_brown_S_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|96cf8feb-0b2b-49e...|     8|    0|       true|            L|    brown|  cardigan_brown_L_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|50e96bc9-2835-43d...|     8|    0|       true|            M|    brown|  cardigan_brown_M_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|ec5dfb5d-23bc-43f...|     9|    0|       true|            M|blue_dark|cardigan_blue_dar...|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|cecf6003-73a1-4d9...|     9|    0|       true|           XL|    beige| cardigan_beige_XL_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|57fb4566-530d-46e...|     9|    0|       true|            S|    black|  cardigan_black_S_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|b23ec26f-b571-46c...|     9|    0|       true|          XXL|blue_dark|cardigan_blue_dar...|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|10653760-e3b1-421...|     9|    0|       true|            S|    beige|  cardigan_beige_S_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|acb83c8b-288d-462...|     9|    0|       true|           XS|blue_dark|cardigan_blue_dar...|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|e56134e3-584a-42e...|     9|    0|       true|           XL|blue_dark|cardigan_blue_dar...|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|b595246f-9569-426...|     9|    0|       true|            L|blue_dark|cardigan_blue_dar...|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|6e0015ac-225a-4c2...|     9|    0|       true|           XS|    beige| cardigan_beige_XS_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|24892775-57ae-429...|     9|    0|       true|            M|    beige|  cardigan_beige_M_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|b55e860b-7e1e-443...|     9|    0|       true|            L|    beige|  cardigan_beige_L_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|97b306bc-5a92-434...|     9|    0|       true|            S|blue_dark|cardigan_blue_dar...|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|7104625e-98cb-49a...|     9|    0|       true|          XXL|    beige|cardigan_beige_XXL_9|      cardigan|   BRAND66|   MAINSTREAM|   55| hip_contour|          false|c6b81db8-29ed-43d...|    hip_contour_55|  2.2|\n",
      "|498662e5-11e8-483...|     8|    0|       true|            M|     ecru|   cardigan_ecru_M_8|      cardigan|  BRAND112|NO_MAINSTREAM|   55| hip_contour|          false|c59807ac-0362-407...|    hip_contour_55|  2.2|\n",
      "+--------------------+------+-----+-----------+-------------+---------+--------------------+--------------+----------+-------------+-----+------------+---------------+--------------------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab4bf8",
   "metadata": {},
   "source": [
    "### Grafo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reglas de unión grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "niveles = {'jumpsuit': '1.1', \n",
    "           'dress': '1.1',\n",
    "           \n",
    "           'jeans': '1.2',\n",
    "           'skirt': '1.2',\n",
    "           'short': '1.2',\n",
    "           'pant': '1.2',\n",
    "          \n",
    "           'shirt': '2.1',\n",
    "           'top': '2.1',\n",
    "           'tshirt': '2.1',\n",
    "          \n",
    "           'sweater': '2.2',\n",
    "           'sweatshirt': '2.2',\n",
    "           'cardigan': '2.2',\n",
    "          \n",
    "           'trench': '3.1',\n",
    "           'coat': '3.1',\n",
    "           'parka': '3.1',\n",
    "           'jacket': '3.1',\n",
    "          \n",
    "           'bag': '3.2',\n",
    "           'scarf': '3.2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3a56f",
   "metadata": {
    "id": "29a3a56f"
   },
   "source": [
    "* Ponderaciones de relaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b1c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "G7, G8, G9 = map(create_graph, [7, 8, 9])\n",
    "G7.name, G8.name, G9.name = 'G7', 'G8', 'G9'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efbc49d2",
   "metadata": {},
   "source": [
    "guardar_pikle(G7, 'G7'), guardar_pikle(G8, 'G8'), guardar_pikle(G9, 'G9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.2'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se genera el modelo para hacer el embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 2079/2079 [04:15<00:00,  8.13it/s]\n"
     ]
    }
   ],
   "source": [
    "node2vec = Node2Vec(G7, dimensions=64, walk_length=10, num_walks=10, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "t10cu_emb = { n: list(map(float,model.wv.get_vector(n))) for n in G7.nodes()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se incluye el embedding en el nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, v  in t10cu_emb.items(): G7.nodes[x]['x'] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otro ejemplo de embedding que no va tan bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnonymousWalkKernel import AnonymousWalks\n",
    "\n",
    "aw = AnonymousWalks(G7)\n",
    "length = 3 # length of the walks\n",
    "\n",
    "aw._all_paths(steps=length)\n",
    "print('All possible anonymous walks of length {} (a.k.a embedding size)'.format(length))\n",
    "print(aw.paths[length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se pasa a formato de pytorch y se divide en train test los edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx, from_networkx, train_test_split_edges\n",
    "G7_torch = from_networkx(G7)\n",
    "G7_torch = train_test_split_edges(G7_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2079, 64], color=[2079], size=[2079], level=[2079], weight=[232104], val_pos_edge_index=[2, 5802], test_pos_edge_index=[2, 11605], train_pos_edge_index=[2, 197290], train_neg_adj_mask=[2079, 2079], val_neg_edge_index=[2, 5802], test_neg_edge_index=[2, 11605])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G7_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se genera una red de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(np.shape(G7_torch.x)[1], 32)\n",
    "        self.conv2 = GCNConv(32, 16)\n",
    "\n",
    "    def encode(self):\n",
    "        x = self.conv1(G7_torch.x, G7_torch.train_pos_edge_index) # convolution 1\n",
    "        x = x.relu()\n",
    "        return self.conv2(x, G7_torch.train_pos_edge_index) # convolution 2\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index): # only pos and neg edges\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z): \n",
    "        prob_adj = z @ z.t() # get adj NxN\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t() # get predicted edge_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data = Net(), G7_torch\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se generan las funciones de entrenamiento y de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    # returns a tensor:\n",
    "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the lenght of pos_edge_index\n",
    "    # and the number of zeros is equal to the length of neg_edge_index\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index, #positive edges\n",
    "        num_nodes=data.num_nodes, # number of nodes\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model.encode() #encode\n",
    "    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index) # decode\n",
    "    \n",
    "    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
    "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "\n",
    "        z = model.encode() # encode train\n",
    "        link_logits = model.decode(z, pos_edge_index, neg_edge_index) # decode test or val\n",
    "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
    "        \n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
    "        \n",
    "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score\n",
    "    return perfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.6568, Val: 0.7777, Test: 0.7782\n",
      "Epoch: 020, Loss: 0.5276, Val: 0.9835, Test: 0.9830\n",
      "Epoch: 030, Loss: 0.4109, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 040, Loss: 0.4033, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 050, Loss: 0.4021, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 060, Loss: 0.3994, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 070, Loss: 0.3980, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 080, Loss: 0.3997, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 090, Loss: 0.3987, Val: 0.9866, Test: 0.9885\n",
      "Epoch: 100, Loss: 0.4000, Val: 0.9866, Test: 0.9885\n"
     ]
    }
   ],
   "source": [
    "best_val_perf = test_perf = 0\n",
    "for epoch in range(1, 101):\n",
    "    train_loss = train()\n",
    "    val_perf, tmp_test_perf = test()\n",
    "    if val_perf > best_val_perf:\n",
    "        best_val_perf = val_perf\n",
    "        test_perf = tmp_test_perf\n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    if epoch % 10 == 0:\n",
    "        print(log.format(epoch, train_loss, best_val_perf, test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode()\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2079, 16]) torch.Size([2, 2344133])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1262, -0.1152,  0.1378,  ..., -0.1502,  0.0401,  0.0829],\n",
       "         [ 0.3043,  0.3897, -0.4060,  ...,  0.2326, -0.2894, -0.3622],\n",
       "         [-0.1365, -0.1140,  0.1249,  ..., -0.1209,  0.0553,  0.0562],\n",
       "         ...,\n",
       "         [-0.1014, -0.1671,  0.1913,  ..., -0.0964,  0.1319,  0.1754],\n",
       "         [ 0.3041,  0.3889, -0.4057,  ...,  0.2324, -0.2892, -0.3616],\n",
       "         [-0.1096, -0.1232,  0.1848,  ..., -0.0959,  0.1130,  0.1857]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[   0,    0,    0,  ..., 2078, 2078, 2078],\n",
       "         [   0,    2,    3,  ..., 2074, 2076, 2078]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(z),np.shape(final_edge_index))\n",
    "z, final_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06804d9",
   "metadata": {},
   "source": [
    "#### Similutud entre grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0d3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grakel.kernels import ShortestPath, WeisfeilerLehman, GraphletSampling, RandomWalk\n",
    "from grakel.datasets import fetch_dataset\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import grakel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in, dir_out = \"../../datos/datos_originales/\", \"../../datos/datos_desarrollo/\"\n",
    "def guardar_pikle(df, name):\n",
    "    with open(dir_out + str(name) + '.pkl', 'wb') as fp: pickle.dump(df, fp)\n",
    "\n",
    "def abrir_pikle(name):\n",
    "    with open(dir_out + str(name) + '.pkl', 'rb') as fp: df = pickle.load(fp)\n",
    "    return df\n",
    "    \n",
    "MUTAG = fetch_dataset (\"MUTAG\", verbose = False )\n",
    "G , y = MUTAG.data , MUTAG.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe7d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G7, G8, G9 = abrir_pikle('G7'), abrir_pikle('G8'), abrir_pikle('G9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ab9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWeisfeiler, modelShortest, modelGraphlet = WeisfeilerLehman(), ShortestPath(), GraphletSampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d9041",
   "metadata": {},
   "source": [
    "Note also that GraKeL contains implementations of kernels between graphs (i.e., kernels that compare graphs to each other). Therefore, feeding a single graph to the fit_transform() function will just produce a single number (i.e., the kernel value between the input graph and itself). Furthermore, the shortest path kernel expects the input graphs to contain node labels. If they do not, you should set the parameter with_labels=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5687586., 3525461., 4187966.],\n",
       "       [3525461., 4562004., 3684795.],\n",
       "       [4187966., 3684795., 6146298.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1104898.,  800312.,  878110.],\n",
       "       [ 800312.,  795222.,  731992.],\n",
       "       [ 878110.,  731992.,  935046.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1396100., 1191908., 1338701.],\n",
       "       [1191908., 1292412., 1288788.],\n",
       "       [1338701., 1288788., 1638196.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in ['level','color', 'size']:\n",
    "    Grakel = grakel.graph_from_networkx([G7, G8, G9], node_labels_tag=x, edge_labels_tag='weight')\n",
    "    display(modelWeisfeiler.fit_transform(Grakel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estos modelos tardan muchisimo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea5d4819",
   "metadata": {},
   "source": [
    "Grakel = grakel.graph_from_networkx([G7, G8, G9], node_labels_tag='color', edge_labels_tag='weight')\n",
    "modelGraphlet.fit_transform(Grakel)\n",
    "\n",
    "Grakel = grakel.graph_from_networkx([G7, G8, G9], node_labels_tag='color', edge_labels_tag='weight')\n",
    "modelShortest.fit_transform(Grakel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(G7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ec0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of G7 and G8: 6059508.999999985\n",
      "Similarity of G7 and G9: 2912325.999999974\n",
      "Similarity of G8 and G9: 5538741.999999972\n"
     ]
    }
   ],
   "source": [
    "def select_k(spectrum, minimum_energy = 0.5):\n",
    "    running_total = 0.0\n",
    "    total = sum(spectrum)\n",
    "    if total == 0.0:\n",
    "        return len(spectrum)\n",
    "    for i in range(len(spectrum)):\n",
    "        running_total += spectrum[i]\n",
    "        if running_total / total >= minimum_energy:\n",
    "            return i + 1\n",
    "    return len(spectrum)\n",
    "\n",
    "for x in [[G7, G8], [G7, G9], [G8, G9]]:\n",
    "    laplacian1 = nx.spectrum.laplacian_spectrum(x[0])\n",
    "    laplacian2 = nx.spectrum.laplacian_spectrum(x[1])\n",
    "\n",
    "    k1 = select_k(laplacian1)\n",
    "    k2 = select_k(laplacian2)\n",
    "    k = min(k1, k2)\n",
    "\n",
    "    similarity = sum((laplacian1[:k] - laplacian2[:k])**2)\n",
    "    print(f'Similarity of {x[0].name} and {x[1].name}: {similarity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2707997",
   "metadata": {},
   "source": [
    "* Se han empleado otros métodos de similitud entre grafos, pero dado la longitud de los grafos resultan muy costosos   \n",
    "\n",
    "<center> \n",
    "<img  src=\"../imagenes/networkx_similarity.PNG\" height = 500> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph statitiscs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ff6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodos</th>\n",
       "      <th>aristas</th>\n",
       "      <th>grados_medio</th>\n",
       "      <th>isolated</th>\n",
       "      <th>closeness_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2079</td>\n",
       "      <td>116052</td>\n",
       "      <td>111.642136</td>\n",
       "      <td>1342</td>\n",
       "      <td>0.228668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870</td>\n",
       "      <td>53935</td>\n",
       "      <td>57.684492</td>\n",
       "      <td>1286</td>\n",
       "      <td>0.190561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2185</td>\n",
       "      <td>125528</td>\n",
       "      <td>114.899771</td>\n",
       "      <td>1396</td>\n",
       "      <td>0.230245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodos  aristas  grados_medio  isolated  closeness_mean\n",
       "0   2079   116052    111.642136      1342        0.228668\n",
       "1   1870    53935     57.684492      1286        0.190561\n",
       "2   2185   125528    114.899771      1396        0.230245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "variables = []\n",
    "for x in [G7, G8, G9]:\n",
    "    nodos = x.number_of_nodes()\n",
    "    aristas = x.number_of_edges()\n",
    "    grados_medio = (x.number_of_edges() / x.number_of_nodes()) * 2\n",
    "    isolated = len([n for n, d in x.degree() if d == 0])\n",
    "\n",
    "    closeness = nx.closeness_centrality(x, wf_improved=False)\n",
    "    closeness_mean = np.array(list(closeness.values())).mean()\n",
    "    variables.append([nodos, aristas, grados_medio, isolated, closeness_mean])\n",
    "\n",
    "pd.DataFrame(variables, columns = ['nodos', 'aristas', 'grado_medio', 'isolated', 'closeness_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb7200",
   "metadata": {},
   "source": [
    "* Número de nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71be7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el grafo de la temporada 7 hay 2079 nodos y 116052 edges\n",
      "En el grafo de la temporada 8 hay 1870 nodos y 53935 edges\n",
      "En el grafo de la temporada 9 hay 2185 nodos y 125528 edges\n"
     ]
    }
   ],
   "source": [
    "for a, n in zip([G7, G8, G9], [7, 8, 9]): \n",
    "    print(f'En el grafo de la temporada {n} hay {a.number_of_nodes()} nodos y {a.number_of_edges()} edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849ee61",
   "metadata": {},
   "source": [
    "**Plotear grafo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755e9228",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib required for draw()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\graph_grakel\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-081d4ea98cc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\graph_grakel\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Matplotlib required for draw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Matplotlib unable to open display\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Matplotlib required for draw()"
     ]
    }
   ],
   "source": [
    "nx.draw(G7, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eb729d9847d079dc3a83fb04234ab0b883f85e4ec6aa38230e8b7f84fe4a950"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('reto10_rojo': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
