{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5c/Logo_Mondragon_Unibertsitatea.png\" width=\"150\" height=\"100\" float =\"left\">\n",
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPIAAADQCAMAAAAK0syrAAAAgVBMVEX///8AAAD7+/t6enrV1dWYmJjj4+Po6OjQ0NDx8fGIiIjq6ur39/fv7+/09PTf39+vr69xcXHGxsa5ubmfn59paWmnp6eTk5M8PDxZWVm9vb1eXl5ubm7BwcEzMzOHh4cnJycdHR0TExNPT09FRUUYGBhaWlpEREQ4ODgqKipjY2MMKFclAAAEmElEQVR4nO3ZaXOyPBQGYG52VzbFfQO1tf//Bz5JqArYzvSd8IK29/Whg4ymJyQ5WTAMIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiKiXyXYdB1B2yxg0nUM7VoBWHcdRKumiO2/1cozbIwQQddhtMhH3zDO6DqMFpnYGsYYTtdxtGiKkWHs0Os6jvb4SA1jhGnXcbRoL7q1kcPrOo72JHANka6truNokazsGH8pXacwDeMNftdxtEjOTX3MdIrworipaNowET16g4VWGXvYDUXTCjFBBXIloiHU6yNtm8HwcDC1ynit1Gci7GGvV+PwtXZgMwSYa5YB6D2ylgH40Cyij10jobQkhXa8Lmor1WR/S/+2P9QsvXEBsNQtY4u8/DE+wHI/rzd4uv3oBPprrj5QWoaICjulge2FI93yG9WbN3C+F6M0Q9nbp2vVihRRqn3YNcK97wZ5MxU2jeR/OVC3T6JPL7SXEJmocnGW4p7l8Zm2wS5aA1EDJdULXqj4tLP129zEWV4EC6zqw3ZQydaelVuPfcq03crHqdy6zxp5eBWjCIuBIc9/NPc/K5i23FD4C6wfjlQmyEqfQsBaVKaHvhgGlugkSG63bNUGNrDXi6vOXeOteNwp9GbNHCNR63hzAeaPJ4WV2SDFxRSPuLT78ETuPItnHhxw/GzpQC1cZzjhoBVXjZ8jv270rB8P5SB10tivbhA9bE25DrmyqqtOq3ywJL42NHoZxvdbB/kb1cvEVJkve+qWvbQwFVVvbiz3ROnRffDk7z/7meiUKsByfjd3Kj1PcViqqoq+XTkT7pcX3l6GhR/hXOpUC1nedTcSi4yl/sV+HYpCjo29NVnmQFpuisNPzgWGM8gj3yUsb4fT8BbjWlZwUNqSTHC6/0rU6NbI40g9r6jcSXJ5p7xqG3oDBxd1GTW0+15+iCBqRxff9h/Pes+wSkbmQP5MtYWqgdyD7PrRu5iLiy5qlU9DrNsGxYPIS2Fx7Voi/75Vj09tzEWOQj3FA33T9OcNzO4j3zmK+j4uLb+bo0LZBPtihB6LfBqh+LuyVqtdeM3O4+ppykV2B0O2dyI69lFcDSYH7Mayjtl9PMVH+T08zkQj1fYfbv3+z02BbLtVcTtfDo5vquxAheOLlHtNN+Mivkst3/VLE4yhlmLis53Jpu8VT2xbPAS5Ll0lgRvETo6tav9088Um23Q1Xx/44WTmhPG3pXx9WC/GbjFCrXsWWapuWn//bNYPgMRT+phfW2+ThuWtY7JSfWeaDv5bJZr15Vh2EDvFOLRwiy5RGeXw0Mj1PGMv8tlTv8vD6vFeKBYQoZov3VInGIsuuzyh2kAuXu9VZfY4LydyNIYyZ/qVo225R6w3afiZrV7J40YqVF1apJ7JtPml/TOY1d8xTD7X/fY8izSmiifm11J2/w+8issqCyC1V/3tNqUl8vhS3uf8XtZtaZ98NWP9SmKpFQ6NYbLXP89+GcGHXAeeXm+G1RIET/cWhYiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIqFn/AA1nKx7ECwr8AAAAAElFTkSuQmCC\" width=\"200\" height=\"120\" float =\"left\">    \n",
    "\n",
    "\n",
    "---\n",
    "<h3>Beñat Basabe, Jon Jarrín, June Pagaldai, Daniel Puente, Eneko Rentería | <font color='red'> Equipo Rojo<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis inicial\n",
    "En este script se detallarán los descriptivos obtenidos de este primer análisis. Tareas como detectar **cantidad de valores missing** o **outliers** entre otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from pyspark.sql.functions import split\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pyspark.sql.functions import when\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases a utilizar\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clase para **cargar de datos** (cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se fijan los **directorios** de entrada y salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in, dir_out = \"../../datos/datos_originales/\", \"../../datos/datos_desarrollo/\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"how to read csv file\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class carga_datos:\n",
    "    ''' Cargar los datos desde el csv al python:\n",
    "    - subir_tablas: se suben los dataframes con los titulos deseados. Como input: una lista de dfs y una lista de titulos.\n",
    "    - subir_una_tabla: como input se especifica la tabla a subir.\n",
    "    '''\n",
    "    def __init__(self, dir_in = dir_in):\n",
    "        self.dir_in = dir_in\n",
    "        \n",
    "    def subir_tablas(self, dir_in):\n",
    "        path = os.getcwd()\n",
    "        csv_files, dataframes_list = glob.glob(os.path.join(path, dir_in + \"*.csv\")), []\n",
    "\n",
    "        for i in csv_files:\n",
    "            temp_df = spark.read.csv(path = i, header = True, inferSchema = True)\n",
    "            dataframes_list.append(temp_df)\n",
    "        \n",
    "        return dataframes_list\n",
    "    \n",
    "    def subir_una_tabla(self, dir_in, nombre_tabla):\n",
    "        return pd.read_csv(os.path.join(dir_in, nombre_tabla + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = carga_datos ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones a utilizar\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Función para **dar nombre** a la variable **family_id** mediante la variable title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_name(id_):\n",
    "    \n",
    "    filtered = product[product.family_id == id_]\n",
    "    string = ' '.join(filtered.title).lower()\n",
    "    \n",
    "    return id_, Counter(string.split()).most_common(1)[0][0]\n",
    "\n",
    "def get_family_name(id_):\n",
    "    \n",
    "    filtered = product.filter(product.family_id == id_)\n",
    "    string = ' '.join([x['title'] for x in filtered.select('title').collect()]).lower()\n",
    "    \n",
    "    return id_, Counter(string.split()).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = cd.subir_tablas(dir_in)\n",
    "titulos = os.listdir(dir_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = cd.subir_una_tabla(dir_in, 'size')\n",
    "size.to_csv(dir_out + 'size2.csv', sep = ';')\n",
    "dfs[-1] = spark.read.csv(path = dir_out + 'size2.csv', header = True, inferSchema = True, sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unión de *dataframes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "<img  src=\"../imagenes/diagrama.PNG\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) df_total =  product variant + color + size + season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Season**: No utilizar\n",
    "- **Size**: Utilizar solo la talla creada por *lookiero*\n",
    "- **Color**: Utilizar solo el nombre del color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product_variant + size = 116 not used sizes NAN  \n",
    "product_variant_size + color = 1 not used color (mixt) NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|        channels|count|\n",
      "+----------------+-----+\n",
      "|              []|  274|\n",
      "|\"[\"\"LOOKIERO\"\"]\"| 2658|\n",
      "+----------------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|number|count|\n",
      "+------+-----+\n",
      "|     0|  163|\n",
      "+------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|       unit|count|\n",
      "+-----------+-----+\n",
      "| PERCENTAGE|    1|\n",
      "|CENTIMETERS|    8|\n",
      "|         \\N|   52|\n",
      "+-----------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|season|count|\n",
      "+------+-----+\n",
      "|     9|20522|\n",
      "|     7|22234|\n",
      "|     8|22470|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs[7].groupBy('channels').count().orderBy('count').show()\n",
    "dfs[0].groupBy('number').count().orderBy('count').show()\n",
    "dfs[3].groupBy('unit').count().orderBy('count').show()\n",
    "dfs[-3].groupBy('season').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brand.csv', 'color.csv', 'datos_envios_MU.csv', 'feature.csv', 'feature_qualifier.csv', 'feature_value.csv', 'feature_value_family.csv', 'product.csv', 'product_feature_value.csv', 'product_feature_value_qualifier.csv', 'product_variant.csv', 'season.csv', 'size.csv']\n"
     ]
    }
   ],
   "source": [
    "print(titulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, suffix):\n",
    "    ''' Renombra las columnas de un dataframe.'''\n",
    "    for names in df.schema.names: df = df.withColumnRenamed(names,names + suffix)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We rename the columnas to have a suffix when we join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[-1] = rename_columns(dfs[-1], '_size')\n",
    "dfs[1] = rename_columns(dfs[1], '_color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se junta los 2 dataframes en uno solo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = dfs[10].join(dfs[-1].select('id_size','lookiero_size'), dfs[10].size_id == dfs[-1].id_size, \"inner\").drop('id_size', 'size_id')\n",
    "df_total = df_total.join(dfs[1].select('id_color', 'name_color'), df_total.color_id == dfs[1].id_color).drop('id_color', 'color_id', 'legacy_id')\n",
    "df_total = df_total.withColumnRenamed(\"lookiero_size\",\"size_lookiero\") \\\n",
    "    .withColumnRenamed(\"name_color\",\"color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se modifica la variable size_lookiero para que tenga formato numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.withColumn('size_lookiero', split(df_total['size_lookiero'], ':').getItem(1))\n",
    "df_total = df_total.withColumn('size_lookiero', regexp_replace('size_lookiero', '\"\"', ''))\n",
    "df_total = df_total.withColumn('size_lookiero', regexp_replace('size_lookiero', '}', ''))\n",
    "df_total = df_total.withColumn('size_lookiero', split(df_total['size_lookiero'], ',').getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='e652ced0-571b-4ebe-a349-47155e190141', barcode=1281248, product_id='fa14ec83-b053-466e-afc0-ac164b77750f', season=9, stock=0, publishable='t', size_lookiero=' S', color='black')\n"
     ]
    }
   ],
   "source": [
    "print(df_total.collect()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) df_total += product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Product**: Dar nombre a la variable family_id y eliminar *legacy_id* y *channels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product_variant + product = 41291 (63'3%) with no product_family or brand NAN  \n",
    "NO SÉ SI SON COAT, SCARF O QUÉ...  \n",
    "23935 SIN NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = dfs[7].drop('legacy_id', 'channels')\n",
    "\n",
    "unique_values_family =  [x['family_id'] for x in product.select('family_id').distinct().collect()]\n",
    "parejas = dict(map(get_family_name, unique_values_family))\n",
    "product = product.withColumn(\"product_family\", product[\"family_id\"])\n",
    "\n",
    "# Este es el mapeado\n",
    "for k, v in enumerate(unique_values_family): \n",
    "    product = product.withColumn('product_family', regexp_replace('product_family', v, str(parejas[v])))\n",
    "\n",
    "# Se renombra la columna a la hora de unir\n",
    "product = product.drop('family_id', 'title', '\"\"\"group\"\"\"')\n",
    "product = rename_columns(product, '_product')\n",
    "\n",
    "df_total = df_total.join(product, df_total.product_id == product.id_product).drop('product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) df_total += brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **brand**: No utilizar variable number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_total + brand = 0 NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = dfs[0].drop('number')\n",
    "brand = brand.withColumnRenamed(\"id\",\"id\").withColumnRenamed(\"name\",\"brand\").withColumnRenamed(\"origin\",\"brand_origin\")\n",
    "df_total = df_total.withColumn(\"publishable\", when(df_total.publishable == \"f\",False).when(df_total.publishable == \"t\",True))\n",
    "brand = rename_columns(brand, '_brand')\n",
    "df_total = df_total.join(brand, df_total.brand_id_product == brand.id_brand).drop('brand_id_product','brand_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) values = feature values + feature (*value caracteristics*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **feature**: Multiple convertir en booleano (borrar??) y para poder eliminar la variable unit pasar los porcentajes a decimales (para diferenciarlos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature + feature_value = 1 value caracteristic not used NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dfs[3]\n",
    "feature = feature.withColumn(\"multiple\", when(feature.multiple == \"f\",False).when(feature.multiple == \"t\",True))\n",
    "column_names = ['id', 'feature_name', 'feature_type', 'feature_multiple', 'unit']\n",
    "\n",
    "for k, v in enumerate(column_names):  feature = feature.withColumnRenamed(feature.schema.names[k], v)\n",
    "feature_value = dfs[5]\n",
    "feature = rename_columns(feature, '_values')\n",
    "values = feature_value.join(feature, feature_value.feature_id == feature.id_values).drop('feature_id','id_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hay que corregirlo pero no sé cómo**\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "| 0.25|\n",
      "| 0.36|\n",
      "| 0.93|\n",
      "| 0.46|\n",
      "+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values.select('value').filter(values.unit_values == 'PERCENTAGE').withColumn('value', f.col('value')/100).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_family no sirve para nada **creo** por lo que las siguientes celda en raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) values + value family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in enumerate(['feature_family', 'feature_value_id']):  dfs[6] = dfs[6].withColumnRenamed(dfs[6].schema.names[k], v)\n",
    "values = values.join(dfs[6], values.id == dfs[6].feature_value_id).drop('feature_value_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) product_values = values + product_feature_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "values + product_feature_value = 1420 (1'84%) caracteristics that has no product NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = values.withColumnRenamed('id', 'id_values')\n",
    "dfs[8] = dfs[8].withColumnRenamed('id', 'id_product_feature')\n",
    "product_values = values.join(dfs[8], values.id_values == dfs[8].feature_value_id).drop('feature_value_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) product_values + df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "products + features = 383 (0'06%) products without caracteristics NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_total.join(product_values, df_total.id_product == product_values.product_id).drop('product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id = Un único producto (se repite pork tiene diferentes features)  \n",
    "id_product = El producto en general (niki manga larga)  \n",
    "id_values = id de una característica\n",
    "id_product_feature = id de la característica de un producto en general (id_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------+-----+-----------+-------------+-----+--------------------+----------------------+--------------------+-----------+------------------+--------------------+-----+-------------------+-------------------+-----------------------+-----------+--------------------+--------------------+\n",
      "|                  id|barcode|season|stock|publishable|size_lookiero|color|          id_product|product_family_product|            id_brand|brand_brand|brand_origin_brand|           id_values|value|feature_name_values|feature_type_values|feature_multiple_values|unit_values|      feature_family|  id_product_feature|\n",
      "+--------------------+-------+------+-----+-----------+-------------+-----+--------------------+----------------------+--------------------+-----------+------------------+--------------------+-----+-------------------+-------------------+-----------------------+-----------+--------------------+--------------------+\n",
      "|498662e5-11e8-483...| 949392|     8|    0|       true|            M| ecru|30c9f937-4bbc-48d...|              cardigan|c373a4f2-a8de-41e...|   BRAND112|     NO_MAINSTREAM|01361580-1c09-483...|   55|        hip_contour|             NUMBER|                  false|CENTIMETERS|c6b81db8-29ed-43d...|21731466-e726-40a...|\n",
      "|dcda2fe4-58e3-4b2...| 949385|     8|    0|       true|            S| ecru|30c9f937-4bbc-48d...|              cardigan|c373a4f2-a8de-41e...|   BRAND112|     NO_MAINSTREAM|01361580-1c09-483...|   55|        hip_contour|             NUMBER|                  false|CENTIMETERS|c6b81db8-29ed-43d...|21731466-e726-40a...|\n",
      "|d54e064c-9f90-4ea...| 949408|     8|    0|       true|            L| ecru|30c9f937-4bbc-48d...|              cardigan|c373a4f2-a8de-41e...|   BRAND112|     NO_MAINSTREAM|01361580-1c09-483...|   55|        hip_contour|             NUMBER|                  false|CENTIMETERS|c6b81db8-29ed-43d...|21731466-e726-40a...|\n",
      "|3112fc7f-5b4d-4c3...| 949354|     8|    0|       true|            S|brown|30c9f937-4bbc-48d...|              cardigan|c373a4f2-a8de-41e...|   BRAND112|     NO_MAINSTREAM|01361580-1c09-483...|   55|        hip_contour|             NUMBER|                  false|CENTIMETERS|c6b81db8-29ed-43d...|21731466-e726-40a...|\n",
      "|96cf8feb-0b2b-49e...| 949378|     8|    0|       true|            L|brown|30c9f937-4bbc-48d...|              cardigan|c373a4f2-a8de-41e...|   BRAND112|     NO_MAINSTREAM|01361580-1c09-483...|   55|        hip_contour|             NUMBER|                  false|CENTIMETERS|c6b81db8-29ed-43d...|21731466-e726-40a...|\n",
      "+--------------------+-------+------+-----+-----------+-------------+-----+--------------------+----------------------+--------------------+-----------+------------------+--------------------+-----+-------------------+-------------------+-----------------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
